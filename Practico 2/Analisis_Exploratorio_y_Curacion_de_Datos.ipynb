{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiploDatos 2020 - Coronavirus en Argentina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctico Análisis Exploratorio y Curación de Datos\n",
    "\n",
    "Database: https://github.com/lucia15/Datos-Covid19-Argentina\n",
    "\n",
    "### Tareas a realizar:\n",
    "\n",
    "* Detectar al menos **tres** variables con valores faltantes no triviales. Decidir qué tratamiento darles (eliminarlos, computarlos, etc.), investigar los métodos disponibles en pandas para dichos fines.\n",
    "\n",
    "* Detectar al menos **cinco** inconsistencias en los datos, discutir a qué se deben y qué podemos hacer con ellas.\n",
    " \n",
    "* Elegir al menos **una** variable que tenga outliers, debatir y decidir qué hacer con los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empezamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aumentar el ancho del notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seteamos semilla random para reproducibilidad\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialización y carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/lucia15/Datos-Covid19-Argentina/master/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = os.path.join(url, 'Argentina-covid19.csv')\n",
    "\n",
    "data1 = pd.read_csv(file1, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = os.path.join(url, 'Argentina-covid19-por-provincia.csv')\n",
    "\n",
    "data2 = pd.read_csv(file2, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3 = os.path.join(url, 'Argentina-covid19-fallecidos.csv')\n",
    "\n",
    "data3 = pd.read_csv(file3, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar, es necesario repasar cuáles son las variables que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la cantidad de filas y columnas\n",
    "print(\"Cantidad de registros: \", data1.shape[0])\n",
    "print(\"Cantidad de columnas: \", data1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listamos las columnas y sus tipos de datos\n",
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisar en https://github.com/lucia15/Datos-Covid19-Argentina de qué se trataba cada una"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el tipo de la columna 'fecha' de object a datetime\n",
    "data1['fecha'] = pd.to_datetime(data1['fecha'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1.head()\n",
    "#data1.tail()\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hacer lo mismo con los otros datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de registros: \", data2.shape[0])\n",
    "print(\"Cantidad de columnas: \", data2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['fecha'] = pd.to_datetime(data2['fecha'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de registros: \", data3.shape[0])\n",
    "print(\"Cantidad de columnas: \", data3.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['fecha'] = pd.to_datetime(data3['fecha'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunas ideas para arrancar con el análisis\n",
    "\n",
    "Como en el práctico anterior, estas son solo ayudas y sugerencias.\n",
    "\n",
    "## Valores faltantes\n",
    "\n",
    "El siguiente comando imprime True en los campos con valor NaN (not a number) y False donde sí hay asignado un valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar por ejemplo que no falta ninguna fecha desde el 2020-03-05 hasta la actualidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['fecha'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo vemos que en este dataset faltan un montón de otros valores, principalmente entre los primeros días, esto se debe a que los primeros informes diarios tenían menos información. A medida que fueron pasando los días se incorporaron variables que tuvieron valores desde ese momento en adelante. \n",
    "\n",
    "Por ejemplo, la variable 'dia_cuarentena' tiene valores a partir del día 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['dia_cuarentena'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el día en que se declara la cuarentena por DNU 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['fecha'][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valores en días anteriores no tendrían sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos interesa detectar valores faltantes a partir del momento en que la variable tiene su primer valor, no antes.\n",
    "\n",
    "Por ejemplo, para la variable '%mujer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['%mujer'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vemos que hasta el día 20 esta variable no tiene valores, posiblemente porque estos se empezaron a reportar a partir del día 21, ¿pero qué pasó en el día 106?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[105:108]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el campo 'observaciones' vemos que el Reporte Matutino correspondiente a ese día no fue publicado en la página https://www.argentina.gob.ar/coronavirus/informe-diario/junio2020, y este es el Reporte que debía contener dicha información faltante.\n",
    "\n",
    "#### TO DO:\n",
    "\n",
    "* ¿Podemos completar este campo con algún valor? Hint: chequear las funciones *fillna()*, *replace()*, *interpolate()*\n",
    "\n",
    "* ¿Qué otras variables están en una situación similar? ¿Podemos completarlas también?\n",
    "\n",
    "* Buscar datos faltantes en los otros dos datasets y evaluar si es posible o no completarlos\n",
    "\n",
    "Para más detalles leer los siguients artículos (si tienen tiempo):\n",
    "\n",
    "* https://www.geeksforgeeks.org/working-with-missing-data-in-pandas/\n",
    "\n",
    "* https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b\n",
    "\n",
    "* https://towardsdatascience.com/the-ultimate-guide-to-data-cleaning-3969843991d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['casos_nuevos'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['casos_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['%varon'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['mujer_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['varon_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['franja_etaria'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[124:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['edad_prom'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['importados_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['importados_nuevos'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['local_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['local_nuevos'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['comunitario_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['comunitario_nuevos'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que faltan los primeros 28 días, quizá sea posible reemplazar por 0, si corresponde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['en_investigacion_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['en_investigacion_nuevos'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['muertes_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['muertes_nuevos'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['alta_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[104:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_corregido = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá se  corrige el faltante en altas nuevas debido a que se arrastra el faltante del reporte del 20 de Junio.\n",
    "\n",
    "for k in range(108,132):\n",
    "    data1_corregido['alta_nuevos'][k] = data1_corregido['alta_total'][k]-data1_corregido['alta_total'][k-1]\n",
    "    \n",
    "# Además se podría incluir las altas nuevas del 20 de Junio donde no hay dato, con las del 21, aunque no es correcto sumamos consistencia al dataset\n",
    "\n",
    "data1_corregido['alta_nuevos'][107] = data1_corregido['alta_total'][107]-data1_corregido['alta_total'][107-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1_corregido['alta_nuevos'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['alta_nuevos'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['alta_definitiva'].isnull()\n",
    "#df[df==True]\n",
    "df[df==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['descartados_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[31:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['descartados_nuevos'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['tests_realizados_total'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['tests_realizados_nuevos'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['test_por_millon_hab'].isnull()\n",
    "df[df==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['UTI_internados'].isnull()\n",
    "#df[df==True]\n",
    "df[df==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['UTI_%Nacion'].isnull()\n",
    "#df[df==True]\n",
    "df[df==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1['UTI_%AMBA'].isnull()\n",
    "#df[df==True]\n",
    "df[df==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[110:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1[ data1['observaciones'].isnull() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores faltantes - dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data3_columns = data3.columns\n",
    "for column in data3_columns:\n",
    "    print('Columna: ', column)    \n",
    "    df = data3[column].isnull()\n",
    "    cant_nulos = df[df==True].size\n",
    "    print('Cantidad de valores faltantes: ', cant_nulos)\n",
    "    print('Cantidad de total de valores: ', data3.shape[0])\n",
    "    print('Porcentaje valores faltantes: ', round(((cant_nulos / data3.shape[0]) * 100), 3), '%')\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis valores faltantes Dataset 3\n",
    "\n",
    "Tras ver los valores de datos faltantes de todas las columnas del dataset, podemos dividirlos en 3 grupos: **Sin datos faltantes**, **Con pocos faltantes**, **Con muchos faltantes**\n",
    "\n",
    "- **Sin datos faltantes**: dentro de este grupo podemos incluir a las columnas que no presentan datos faltantes. Las columnas que pertenecen a este grupo son: **fecha** y **num_caso**.\n",
    "- **Con pocos faltantes**: dentro de este grupo incluímos a las columnas que que cuentan con aproximadamente un 5% de datos faltantes. Las columnas que pertenecen a este grupo son: **provincia**, **genero** y **edad**.\n",
    "- **Con muchos faltantes**: dentro de este grupo incluímos a las columnas que que cuentan con más del 90% de datos faltantes. Las columnas que pertenecen a este grupo son: **tipo_caso**, **comorbilidades**, **viajes** y **observaciones**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento valores faltantes Dataset 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con pocos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columna provincia\n",
    "pd.set_option('display.max_rows', data3.shape[0]+1)\n",
    "data3[data3.provincia.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Columna genero\n",
    "pd.set_option('display.max_rows', data3.shape[0]+1)\n",
    "data3[data3.genero.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columna edad\n",
    "pd.set_option('display.max_rows', data3.shape[0]+1)\n",
    "data3[data3.edad.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sin datos en la columna provincia, genero y edad:\n",
    "data3[data3.provincia.isnull() & data3.genero.isnull() & data3.edad.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faltantes_observaciones = data3[data3.provincia.isnull() & data3.genero.isnull() & data3.edad.isnull()].observaciones.isnull()\n",
    "cant_sin_observaciones = faltantes_observaciones[faltantes_observaciones==True].shape[0]\n",
    "cant_sin_observaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con pocos faltantes\n",
    "\n",
    "Como se puede observar, si filtramos el dataset para visualizar las filas que tienen datos faltantes en todas las columnas del grupo **Con pocos faltantes**, podemos observar que todas las filas resultantes tienen completa la columna **observaciones**. En esta columna se indica que estas filas peretenecen a muertes faltantes en los reportes o bien corresponden a datos de reportes no publicados. Es por este motivo que la mayoría de las columnas se encuentran incompletas. Una alternativa de limpieza de estos datos, sería eliminar las filas que no cuentan con datos en estas columnas (**VER**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con muchos faltantes\n",
    "\n",
    "Teniendo en cuenta la gran cantidad de datos faltantes que contienen estas columnas y que los datos de las mismas no corresponden a valores numéricos calculados. Una alternativa para limpiar el conjunto de datos, sería eliminar estas columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistencia de los datos\n",
    "\n",
    "Las variables de cada data set deben ser consistentes. Por ejemplo, el total de infectados para un día dado, debe ser igual al total de infectados del día anterior más los casos nuevos de ese día:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['casos_total'][116] == data1['casos_total'][115] + data1['casos_nuevos'][116]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero además debe ser igual a la suma de todos los casos nuevos hasta ese día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['casos_total'][116] == sum(data1['casos_nuevos'][:117])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos qué está pasando chequeando todos los días:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data1['casos_total'])\n",
    "\n",
    "if data1['casos_total'][0] != data1['casos_total'][0]:\n",
    "    print(0)\n",
    "\n",
    "for k in range(1,n):\n",
    "    \n",
    "    if data1['casos_total'][k] != data1['casos_total'][k-1] + data1['casos_nuevos'][k]:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los días que presentan inconsistencias. Estas pueden deberse, por ejemplo, a descartes o reclasificaciones de casos reportados anteriormente, por lo que no necesariamente hay que \"arreglarlas\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de la coherencia interna de cada dataset, los tres datasets deben ser consistentes entre sí.\n",
    "\n",
    "Por ejemplo, la cantidad de fallecidos al día '2020-06-29' reportado en 'Argentina-covid19.csv' (data1) debe coincidir con el 'num_caso' del último registro de esa fecha en 'Argentina-covid19-fallecidos.csv' (data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[data1['fecha']=='2020-06-29']['muertes_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3[data3['fecha']=='2020-06-29'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los números coinciden, por lo tanto los datos son consistentes.\n",
    "\n",
    "Este valor también debería coincidir con la suma de 'muertes_total' de cada provincia al día '2020-06-29'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[data2['fecha']=='2020-06-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data2[data2['fecha']=='2020-06-29']['muertes_total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso no coinciden... ¿qué puede estar pasando? ¿lo podremos solucionar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué otras inconsistencias encuentran en los datos? ¿Cómo podemos solucionarlas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = float('nan')\n",
    "\n",
    "for i in range(0,len(data1['%mujer'])):\n",
    "    q = round(100*data1['mujer_total'][i]/data1['casos_total'][i],1)\n",
    "    w = round(100*data1['varon_total'][i]/data1['casos_total'][i],1)\n",
    "    #print( i, data1['%mujer'][i], data1['%varon'][i] )\n",
    "    #print( i,\n",
    "    #      data1['casos_total'][i],\n",
    "    #      data1['mujer_total'][i],\n",
    "    #      data1['mujer_total'][i]/data1['casos_total'][i],\n",
    "    #      float(data1['%mujer'][i].replace(',','.')),\n",
    "    #      q )\n",
    "    if ( type(data1['%mujer'][i]) == type('str') ):\n",
    "        if ( q != float(data1['%mujer'][i].replace(',','.')) ):\n",
    "            print( i, 'mujer' )\n",
    "            print( data1['casos_total'][i] ,data1['%mujer'][i], q, data1['mujer_total'][i], data1['%varon'][i], w,  data1['varon_total'][i] )\n",
    "    if ( type(data1['%varon'][i]) == type('str') ):\n",
    "        if ( w != float(data1['%varon'][i].replace(',','.')) ):\n",
    "            print( i, 'varon' )\n",
    "            print( ' ' )\n",
    "    #print( i, \n",
    "    #      '\\t mujer', q == float(data1['%mujer'][i].replace(',','.')),\n",
    "    #      '\\t varon', w == float(data1['%varon'][i].replace(',','.'))\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data1['casos_total'])\n",
    "\n",
    "casos = []\n",
    "for k in range(1,n):\n",
    "    \n",
    "    if data1['muertes_total'][k] != data1['muertes_total'][k-1] + data1['muertes_nuevos'][k]:\n",
    "        print(k,data1['muertes_total'][k], data1['muertes_total'][k-1], data1['muertes_nuevos'][k] )\n",
    "        casos.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inconsistecia del día 30 de Marzo (fila 25). Habían reportados 20 fallecientos en total en el reporte vespertino del día 29, el reporte matutino del día 30 suma un fallecimiento, y el reporte verpertino del mismo día suma cuatro fallecimientos nuevos, pero reporta un total de 24 muertes totales. En este caso la inconsistecia está en la fuente de los datos. En los informes del día siguiente, 31 de Marzo, no se rectifica esta inconsistencia, y se considera que el numero de fallecidos es efectivamente 24. Puede deberse la inconsistencia que el fallecimiento del reporte matutino del 30 haya sido rectificado, en alguno de sus datos, y este incluído en el vespertino. De ser así en el dataset se debería restar un caso al día 29. Sin más información no se puede corregir la inconsistencia.\n",
    "\n",
    "En el caso de los días 2 y 3 de Abril (filas 28 y 29) sucede que hay muertes que se están contando de manera erronea al cargarlas a la base de datos. El criterio parece ser que incluye a las muertes del reporte matutino en el dato de muertes nuevas del día anterior. Por lo que la muertes acumaluadas pueden no coincidir con el dato del reporte vespertino del día. En este caso el reporte vespertinos del 2 de Abril incluye las dos muertes del reporte matutino del mismo día, por lo que de la manera en que sea cargan los datos de se debería corregir el número de muertes nuevas de 4 a 3, las dos del vespertino del 2 y una del matutino del 3 de Abril. Eso hace consistente el dato de 37 muertes el 2/04.\n",
    "\n",
    "El día 3 de Abril sucede de forma distinta al día anterior. En el matutino se reporta una muerte, y luego el vespertino suma 5 muertes sin contar la anterior. En el siguente reporte matutino no hay muertes nuevas, por lo que las muertes de 3 de Abril deben ser 5 en lugar de las 6 que figuran en la base de datos, debido a que la muerte del reporte matutino del mismo día ya había sido contabilizada en las 37 totales del día anterior.\n",
    "\n",
    "Se pueden corregir estas inconsistencias cambiando el número de muertes nuevas los día 2 y 3 de Abril por los correctos.\n",
    "\n",
    "El en día 30 de Abril (fila 56) se puede observar que las muertes acumuladas coinciden con las reportadas en el informe vespertino de ese día. Por otro lado, en el día anterior, las muertes tambien coinciden con las del reporte vespertino de ese día. Podemos asumir que aquí ya se esta usando el criterio de que la entrada de muertes totales coincida con los reportes vespertinos, por lo que las muertes registradas en los reportes matutinos se deben sumar a las del vespertino del mismo día. Entonces, el 30 en el reporte matutino se informa una muertes y en verpertino 3, por lo que el total debe ser de 4 en lugar de 3 como en la base de datos.\n",
    "\n",
    "El caso del día 22 de Mayo (fila 78) presenta una inconsistencia. Las muertes totales del mismo día y del anterior coinciden con los reportes, pero las muertes nuevas no coinciden, se informan 3 en el reporte matutino y 14 en el verpertino, que suman 17, mientras en la base de datos figuran 18.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filter_df  = data1[data1.index.isin(casos)]\n",
    "Filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in casos:\n",
    "    fecha = data1['fecha'][k]\n",
    "\n",
    "    df = data3[data3['fecha']==fecha]\n",
    "    l  = len(df)\n",
    "    q  = df.index[l-1]\n",
    "    \n",
    "    qq = float(data1[data1['fecha']==fecha].get('muertes_total'))\n",
    "    ll = float(data1[data1['fecha']==fecha].get('muertes_nuevos'))\n",
    "    print(fecha, '\\t', q+1, '\\t', l,'\\t','\\t', qq, '\\t', ll )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data1['casos_total'])\n",
    "q = -1\n",
    "for k in range(1,n):\n",
    "    fecha = data1['fecha'][k]\n",
    "\n",
    "    df = data3[data3['fecha']==fecha]\n",
    "    l  = len(df)\n",
    "    if (l!=0):\n",
    "        q  = df.index[l-1]\n",
    "\n",
    "    qq = float(data1[data1['fecha']==fecha].get('muertes_total'))\n",
    "    ll = float(data1[data1['fecha']==fecha].get('muertes_nuevos'))\n",
    "    \n",
    "    if (q+1 != qq or l != ll):\n",
    "        print(fecha, '\\t', q+1, '\\t', l,'\\t','\\t', qq, '\\t', ll )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistencias en la columna 'casos_nuevos' entre dataset 1 y dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar inconsistencias de la columna casos_nuevos entre el dataset 1 y el dataset 2\n",
    "fechas_dataset_1 = pd.unique(data1.fecha)\n",
    "fechas_dataset_2 = pd.unique(data2.fecha)\n",
    "\n",
    "cant_inconsistencias = 0\n",
    "if all(fechas_dataset_1 == fechas_dataset_2):\n",
    "    for fecha in fechas_dataset_1:\n",
    "        casos_nuevos_dataset1 = int(data1[data1.fecha == fecha].casos_nuevos)\n",
    "        casos_nuevos_dataset2 = int(sum(data2[data2.fecha == fecha].casos_nuevos))\n",
    "        if casos_nuevos_dataset1 != casos_nuevos_dataset2:\n",
    "            cant_inconsistencias += 1\n",
    "            fecha_format = pd.to_datetime(str(fecha))\n",
    "            fecha_formatted = fecha_format.strftime('%d/%m/%Y')\n",
    "            msg = f'¡Inconsistencia (fecha {fecha_formatted})! {casos_nuevos_dataset1}(casos nuevos dataset1) != {casos_nuevos_dataset2}(casos nuevos dataset2)'\n",
    "            print(msg)\n",
    "print('*' * 50)\n",
    "print(f'Cantidad total de inconsistencias = {cant_inconsistencias}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistencias en la columna 'casos_total' entre dataset 1 y dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar inconsistencias de la columna casos_total entre el dataset 1 y el dataset 2\n",
    "fechas_dataset_1 = pd.unique(data1.fecha)\n",
    "fechas_dataset_2 = pd.unique(data2.fecha)\n",
    "\n",
    "cant_inconsistencias = 0\n",
    "if all(fechas_dataset_1 == fechas_dataset_2):\n",
    "    for fecha in fechas_dataset_1:\n",
    "        casos_total_dataset1 = int(data1[data1.fecha == fecha].casos_total)\n",
    "        casos_total_dataset2 = int(sum(data2[data2.fecha == fecha].casos_total))\n",
    "        if casos_total_dataset1 != casos_total_dataset2:\n",
    "            cant_inconsistencias += 1\n",
    "            fecha_format = pd.to_datetime(str(fecha))\n",
    "            fecha_formatted = fecha_format.strftime('%d/%m/%Y')\n",
    "            msg = f'¡Inconsistencia (fecha {fecha_formatted})! {casos_total_dataset1}(casos total dataset1) != {casos_total_dataset2}(casos total dataset2)'\n",
    "            print(msg)\n",
    "print('*' * 50)\n",
    "print(f'Cantidad total de inconsistencias = {cant_inconsistencias}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "En el siguiente artículo pueden encontrar varias técnicas para detectar outliers:\n",
    "\n",
    "https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data1['casos_nuevos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_outliers =  data1[ data1['casos_nuevos'] > data1['casos_nuevos'].mean() + 2.0*data1['casos_nuevos'].std() ]\n",
    "\n",
    "data1_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data1.columns:\n",
    "    print(c,type(data1[c][120]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = 'UTI_internados'\n",
    "\n",
    "sns.boxplot(data1[select])\n",
    "print(data1[select].mean(),'+/-$',data1[select].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = 'tests_realizados_nuevos'\n",
    "\n",
    "sns.boxplot(data1[select])\n",
    "print(data1[select].mean(),'+/-$',data1[select].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = 'descartados_nuevos'\n",
    "\n",
    "sns.boxplot(data1[select])\n",
    "print(data1[select].mean(),'+/-$',data1[select].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = 'en_investigacion_nuevos'\n",
    "\n",
    "sns.boxplot(data1[select])\n",
    "print(data1[select].mean(),'+/-$',data1[select].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_outliers_up =  data1[ data1['en_investigacion_nuevos'] > data1['en_investigacion_nuevos'].mean() + 2.0*data1['en_investigacion_nuevos'].std()]\n",
    "\n",
    "data1_outliers_dw =  data1[ data1['en_investigacion_nuevos'] < data1['en_investigacion_nuevos'].mean() - 2.0*data1['en_investigacion_nuevos'].std() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_outliers = pd.concat([data1_outliers_dw, data1_outliers_up])\n",
    "data1_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data1['test_por_millon_hab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
